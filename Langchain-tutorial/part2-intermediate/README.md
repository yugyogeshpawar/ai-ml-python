# Part 2: Building Intelligent Applications

Welcome to Part 2 of the LangChain tutorial. In this section, we will move beyond the basics and explore the components that allow you to build truly intelligent applications that can reason, remember, and interact with external data.

## Topics Covered

1.  **Document Loaders:** Loading data from various sources like text files, PDFs, and websites.
2.  **Text Splitters:** Splitting large documents into smaller, manageable chunks for the LLM.
3.  **Embeddings & Vector Stores:** The core of RAG. We'll learn how to create numerical representations of our text and store them for efficient retrieval.
4.  **Retrievers:** The engine that finds the most relevant documents to answer a user's query.
5.  **Memory:** Giving your chains and agents a memory to remember past interactions.
6.  **Agents and Tools:** The most powerful concept in LangChain, where the LLM itself decides which tools to use to solve a problem.

## Project

At the end of this part, you will build a Question-Answering chatbot that can answer questions based on the content of a specific document (e.g., a PDF). This project will demonstrate the power of Retrieval-Augmented Generation (RAG).

Let's get started with the first topic: [Document Loaders](./01-document-loaders/README.md).
